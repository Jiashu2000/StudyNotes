{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "825b7c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions._\n",
       "import org.apache.spark.sql.SparkSession\n",
       "import org.apache.spark.sql.types._\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.types._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79724f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@45320449\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession\n",
    "    .builder\n",
    "    .appName(\"ch7\")\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60dd0919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [id: bigint, square: bigint]\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.range(1 * 10000000).toDF(\"id\").withColumn(\"square\", $\"id\" * $\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56129560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res0: df.type = [id: bigint, square: bigint]\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29703fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res1: Long = 10000000\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a35e180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: Long = 10000000\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42e6f560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import scala.util.Random\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.util.Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8bc8e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d650f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "states: scala.collection.mutable.Map[Int,String] = Map()\n",
       "items: scala.collection.mutable.Map[Int,String] = Map()\n",
       "rnd: scala.util.Random = scala.util.Random@6b81ef92\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val states = scala.collection.mutable.Map[Int, String]()\n",
    "val items = scala.collection.mutable.Map[Int, String]()\n",
    "val rnd = new scala.util.Random(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa49a8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res4: items.type = Map(2 -> SKU-2, 5 -> SLU-5, 4 -> SKU-4, 1 -> SKU-1, 3 -> SKU-3, 0 -> SKU-0)\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states += (0 -> \"AZ\", 1 -> \"CO\", 2 -> \"CA\", 3 -> \"TX\", 4 -> \"NY\", 5 -> \"MI\")\n",
    "items += (0 -> \"SKU-0\", 1 -> \"SKU-1\", 2 -> \"SKU-2\", 3 -> \"SKU-3\", 4 -> \"SKU-4\",\n",
    "         5 -> \"SLU-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f08ccab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userDF: org.apache.spark.sql.DataFrame = [uid: int, login: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val userDF = (0 to 1000000).map(id => (id, s\"user_${id}\",\n",
    "                                      s\"user_${id}@databricks.com\",\n",
    "                                      states(rnd.nextInt(5)))).toDF(\"uid\", \"login\",\"email\", \"user_state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d985cc25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ordersDF: org.apache.spark.sql.DataFrame = [transaction_id: int, quantity: int ... 4 more fields]\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ordersDF = (0 to 100000).map(r => (r, r, rnd.nextInt(10000), 10 * r * 0.2d,\n",
    "                                      states(rnd.nextInt(5)), items(rnd.nextInt(5))))\n",
    "                            .toDF(\"transaction_id\", \"quantity\", \"user_id\", \"amount\", \"state\", \"items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "852cecbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "usersOrdersDF: org.apache.spark.sql.DataFrame = [transaction_id: int, quantity: int ... 8 more fields]\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val usersOrdersDF = ordersDF.join(userDF, $\"user_id\" === $\"uid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6034b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "usersOrdersDF.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffa8afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "usersOrdersDF.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67001486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
