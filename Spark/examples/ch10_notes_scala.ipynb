{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c5fee9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://172.16.18.84:4040\n",
       "SparkContext available as 'sc' (version = 3.5.0, master = local[*], app id = local-1701475373834)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions._\n",
       "import org.apache.spark.sql.SparkSession\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "128dff9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@3d0ba745\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession\n",
    "    .builder\n",
    "    .appName(\"chapter10\")\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bfe072a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file_path: String = ./data/sf-airbnb/sf-airbnb-clean.parquet/\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val file_path = \"./data/sf-airbnb/sf-airbnb-clean.parquet/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0337737d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airbnbDF: org.apache.spark.sql.DataFrame = [host_is_superhost: string, cancellation_policy: string ... 32 more fields]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val airbnbDF = spark.read.parquet(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "388b12e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---------------+--------+---------+-----------------+-----+\n",
      "|neighbourhood_cleansed|      room_type|bedrooms|bathrooms|number_of_reviews|price|\n",
      "+----------------------+---------------+--------+---------+-----------------+-----+\n",
      "|      Western Addition|Entire home/apt|     1.0|      1.0|            180.0|170.0|\n",
      "|        Bernal Heights|Entire home/apt|     2.0|      1.0|            111.0|235.0|\n",
      "|        Haight Ashbury|   Private room|     1.0|      4.0|             17.0| 65.0|\n",
      "|        Haight Ashbury|   Private room|     1.0|      4.0|              8.0| 65.0|\n",
      "|      Western Addition|Entire home/apt|     2.0|      1.5|             27.0|785.0|\n",
      "+----------------------+---------------+--------+---------+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airbnbDF.select(\"neighbourhood_cleansed\", \"room_type\",\"bedrooms\", \"bathrooms\",\n",
    "               \"number_of_reviews\", \"price\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d1843f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 5780 rows in the training set, and 1366 in the test set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "trainDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [host_is_superhost: string, cancellation_policy: string ... 32 more fields]\n",
       "testDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [host_is_superhost: string, cancellation_policy: string ... 32 more fields]\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Array(trainDF, testDF) = airbnbDF.randomSplit(Array(0.8, 0.2), seed = 42)\n",
    "println(f\"\"\"there are ${trainDF.count} rows in the training set, and ${testDF.count} in the test set\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fb26e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.feature.VectorAssembler\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d3b1e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-----+\n",
      "|bedrooms|features|price|\n",
      "+--------+--------+-----+\n",
      "|     1.0|   [1.0]|200.0|\n",
      "|     1.0|   [1.0]|130.0|\n",
      "|     1.0|   [1.0]| 95.0|\n",
      "|     1.0|   [1.0]|250.0|\n",
      "|     3.0|   [3.0]|250.0|\n",
      "|     1.0|   [1.0]|115.0|\n",
      "|     1.0|   [1.0]|105.0|\n",
      "|     1.0|   [1.0]| 86.0|\n",
      "|     1.0|   [1.0]|100.0|\n",
      "|     2.0|   [2.0]|220.0|\n",
      "+--------+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "vecAssembler: org.apache.spark.ml.feature.VectorAssembler = VectorAssembler: uid=vecAssembler_a5e5214214df, handleInvalid=error, numInputCols=1\n",
       "vecTrainDF: org.apache.spark.sql.DataFrame = [host_is_superhost: string, cancellation_policy: string ... 33 more fields]\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val vecAssembler = new VectorAssembler()\n",
    "    .setInputCols(Array(\"bedrooms\"))\n",
    "    .setOutputCol(\"features\")\n",
    "\n",
    "val vecTrainDF = vecAssembler.transform(trainDF)\n",
    "vecTrainDF.select(\"bedrooms\", \"features\", \"price\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "870189b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.regression.LinearRegression\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.regression.LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0241f3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lr: org.apache.spark.ml.regression.LinearRegression = linReg_8cff2a6dd20a\n",
       "lr_model: org.apache.spark.ml.regression.LinearRegressionModel = LinearRegressionModel: uid=linReg_8cff2a6dd20a, numFeatures=1\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lr = new LinearRegression()\n",
    "    .setFeaturesCol(\"features\")\n",
    "    .setLabelCol(\"price\")\n",
    "\n",
    "val lr_model = lr.fit(vecTrainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a8c58cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the formula for the linear regression line is price = 123.68 * bedroom + 47.51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "m: Double = 123.6757463819947\n",
       "b: Double = 47.51023373378815\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val m = lr_model.coefficients(0)\n",
    "val b = lr_model.intercept\n",
    "\n",
    "println(f\"\"\"the formula for the linear regression line is price = $m%1.2f * bedroom + $b%1.2f\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b5c8b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.Pipeline\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f572fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pipeline: org.apache.spark.ml.Pipeline = pipeline_dded56c77b50\n",
       "pipeline_model: org.apache.spark.ml.PipelineModel = pipeline_dded56c77b50\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pipeline = new Pipeline().setStages(Array(vecAssembler, lr))\n",
    "val pipeline_model = pipeline.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a81acf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+------+------------------+\n",
      "|bedrooms|features| price|        prediction|\n",
      "+--------+--------+------+------------------+\n",
      "|     1.0|   [1.0]|  85.0|171.18598011578285|\n",
      "|     1.0|   [1.0]|  45.0|171.18598011578285|\n",
      "|     1.0|   [1.0]|  70.0|171.18598011578285|\n",
      "|     1.0|   [1.0]| 128.0|171.18598011578285|\n",
      "|     1.0|   [1.0]| 159.0|171.18598011578285|\n",
      "|     2.0|   [2.0]| 250.0|294.86172649777757|\n",
      "|     1.0|   [1.0]|  99.0|171.18598011578285|\n",
      "|     1.0|   [1.0]|  95.0|171.18598011578285|\n",
      "|     1.0|   [1.0]| 100.0|171.18598011578285|\n",
      "|     1.0|   [1.0]|2010.0|171.18598011578285|\n",
      "+--------+--------+------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pred_df: org.apache.spark.sql.DataFrame = [host_is_superhost: string, cancellation_policy: string ... 34 more fields]\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pred_df = pipeline_model.transform(testDF)\n",
    "pred_df.select(\"bedrooms\", \"features\", \"price\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69680962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer}\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b982d0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res7: Array[(String, String)] = Array((host_is_superhost,StringType), (cancellation_policy,StringType), (instant_bookable,StringType), (host_total_listings_count,DoubleType), (neighbourhood_cleansed,StringType), (latitude,DoubleType), (longitude,DoubleType), (property_type,StringType), (room_type,StringType), (accommodates,DoubleType), (bathrooms,DoubleType), (bedrooms,DoubleType), (beds,DoubleType), (bed_type,StringType), (minimum_nights,DoubleType), (number_of_reviews,DoubleType), (review_scores_rating,DoubleType), (review_scores_accuracy,DoubleType), (review_scores_cleanliness,DoubleType), (review_scores_checkin,DoubleType), (review_scores_communication,DoubleType), (review_scores_location,DoubleType), (review_scores_value,DoubleType), (price,DoubleType), (bedrooms_na,DoubleType), (b...\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d391cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "categoricalCols: Array[String] = Array(host_is_superhost, cancellation_policy, instant_bookable, neighbourhood_cleansed, property_type, room_type, bed_type)\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val categoricalCols = trainDF.dtypes.filter(_._2 == \"StringType\").map(_._1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e1fad2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "indexOutputCols: Array[String] = Array(host_is_superhostINDEX, cancellation_policyINDEX, instant_bookableINDEX, neighbourhood_cleansedINDEX, property_typeINDEX, room_typeINDEX, bed_typeINDEX)\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val indexOutputCols = categoricalCols.map(_ + \"INDEX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f4ebcb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "oheOutputCols: Array[String] = Array(host_is_superhostOHE, cancellation_policyOHE, instant_bookableOHE, neighbourhood_cleansedOHE, property_typeOHE, room_typeOHE, bed_typeOHE)\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val oheOutputCols = categoricalCols.map(_ + \"OHE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e8908b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stringIndexer: org.apache.spark.ml.feature.StringIndexer = strIdx_1d6b02434d3d\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val stringIndexer = new StringIndexer()\n",
    "        .setInputCols(categoricalCols)\n",
    "        .setOutputCols(indexOutputCols)\n",
    "        .setHandleInvalid(\"skip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1da3cfd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "oheEncoder: org.apache.spark.ml.feature.OneHotEncoder = oneHotEncoder_bfda03fb8fe8\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val oheEncoder = new OneHotEncoder()\n",
    "    .setInputCols(indexOutputCols)\n",
    "    .setOutputCols(oheOutputCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd13fd82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numericCols: Array[String] = Array(host_total_listings_count, latitude, longitude, accommodates, bathrooms, bedrooms, beds, minimum_nights, number_of_reviews, review_scores_rating, review_scores_accuracy, review_scores_cleanliness, review_scores_checkin, review_scores_communication, review_scores_location, review_scores_value, bedrooms_na, bathrooms_na, beds_na, review_scores_rating_na, review_scores_accuracy_na, review_scores_cleanliness_na, review_scores_checkin_na, review_scores_communication_na, review_scores_location_na, review_scores_value_na)\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val numericCols = trainDF.dtypes.filter{case(field, dataType) => \n",
    "    dataType == \"DoubleType\" && field != \"price\"}.map(_._1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "827bcfe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res14: Array[String] = Array(host_is_superhostOHE, cancellation_policyOHE, instant_bookableOHE, neighbourhood_cleansedOHE, property_typeOHE, room_typeOHE, bed_typeOHE)\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oheOutputCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5302a8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assemblerInputs: Array[String] = Array(host_is_superhostOHE, cancellation_policyOHE, instant_bookableOHE, neighbourhood_cleansedOHE, property_typeOHE, room_typeOHE, bed_typeOHE, host_total_listings_count, latitude, longitude, accommodates, bathrooms, bedrooms, beds, minimum_nights, number_of_reviews, review_scores_rating, review_scores_accuracy, review_scores_cleanliness, review_scores_checkin, review_scores_communication, review_scores_location, review_scores_value, bedrooms_na, bathrooms_na, beds_na, review_scores_rating_na, review_scores_accuracy_na, review_scores_cleanliness_na, review_scores_checkin_na, review_scores_communication_na, review_scores_location_na, review_scores_value_na)\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val assemblerInputs = oheOutputCols ++ numericCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "72e28940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vecAssemble: org.apache.spark.ml.feature.VectorAssembler = VectorAssembler: uid=vecAssembler_a2ba7d18a1b0, handleInvalid=error, numInputCols=33\n"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val vecAssemble = new VectorAssembler()\n",
    "        .setInputCols(assemblerInputs)\n",
    "        .setOutputCol(\"feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4738da6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pipeline_path: String = lr_model_path\n"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pipeline_path = \"lr_model_path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae1e444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model.write.overwrite().save(pipeline_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcea1f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
