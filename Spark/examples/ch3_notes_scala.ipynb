{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bd3f8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://172.16.18.84:4041\n",
       "SparkContext available as 'sc' (version = 3.5.0, master = local[*], app id = local-1701104918260)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions._\n",
       "import org.apache.spark.sql.SparkSession\n",
       "import org.apache.spark.sql.types._\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.types._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "132caef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@7b06ea04\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession\n",
    "    .builder\n",
    "    .appName(\"Example-3_7\")\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "945923a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jsonFile: String = /Users/jiashu/Documents/StudyNotes/spark/examples/data/blogs.json\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val jsonFile = \"/Users/jiashu/Documents/StudyNotes/spark/examples/data/blogs.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0f9b851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schema: org.apache.spark.sql.types.StructType = StructType(StructField(Id,IntegerType,false),StructField(First,StringType,false),StructField(Last,StringType,false),StructField(Url,StringType,false),StructField(Published,StringType,false),StructField(Hits,IntegerType,false),StructField(Campaigns,ArrayType(StringType,true),false))\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val schema = StructType(Array(StructField(\"Id\", IntegerType, false),\n",
    "StructField(\"First\", StringType, false),\n",
    "StructField(\"Last\", StringType, false),\n",
    "StructField(\"Url\", StringType, false),\n",
    "StructField(\"Published\", StringType, false),\n",
    "StructField(\"Hits\", IntegerType, false),\n",
    "StructField(\"Campaigns\", ArrayType(StringType), false)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2af35537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "blogsDF: org.apache.spark.sql.DataFrame = [Id: int, First: string ... 5 more fields]\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val blogsDF = spark.read.schema(schema).json(jsonFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "311509df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------------+---------+-----+----------------------------+\n",
      "|Id |First    |Last   |Url              |Published|Hits |Campaigns                   |\n",
      "+---+---------+-------+-----------------+---------+-----+----------------------------+\n",
      "|1  |Jules    |Damji  |https://tinyurl.1|1/4/2016 |4535 |[twitter, LinkedIn]         |\n",
      "|2  |Brooke   |Wenig  |https://tinyurl.2|5/5/2018 |8908 |[twitter, LinkedIn]         |\n",
      "|3  |Denny    |Lee    |https://tinyurl.3|6/7/2019 |7659 |[web, twitter, FB, LinkedIn]|\n",
      "|4  |Tathagata|Das    |https://tinyurl.4|5/12/2018|10568|[twitter, FB]               |\n",
      "|5  |Matei    |Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB, LinkedIn]|\n",
      "|6  |Reynold  |Xin    |https://tinyurl.6|3/2/2015 |25568|[twitter, LinkedIn]         |\n",
      "+---+---------+-------+-----------------+---------+-----+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blogsDF.show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef04f8f9",
   "metadata": {},
   "source": [
    "#### Columns and Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "287f278d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res1: Array[String] = Array(Id, First, Last, Url, Published, Hits, Campaigns)\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogsDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83eace8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: org.apache.spark.sql.Column = Id\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogsDF.col(\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63913ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|(Hits * 2)|\n",
      "+----------+\n",
      "|      9070|\n",
      "|     17816|\n",
      "+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blogsDF.select(expr(\"Hits * 2\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e29507b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|(Hits * 2)|\n",
      "+----------+\n",
      "|      9070|\n",
      "|     17816|\n",
      "+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blogsDF.select(col(\"Hits\") * 2).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50ec39de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------------+---------+-----+--------------------+-----------+\n",
      "| Id|    First|   Last|              Url|Published| Hits|           Campaigns|big hitters|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+-----------+\n",
      "|  1|    Jules|  Damji|https://tinyurl.1| 1/4/2016| 4535| [twitter, LinkedIn]|      false|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2| 5/5/2018| 8908| [twitter, LinkedIn]|      false|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3| 6/7/2019| 7659|[web, twitter, FB...|      false|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|5/12/2018|10568|       [twitter, FB]|       true|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB...|       true|\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6| 3/2/2015|25568| [twitter, LinkedIn]|       true|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blogsDF.withColumn(\"big hitters\", (expr(\"Hits > 10000\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ae4c51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "| Id|    First|   Last|              Url|Published| Hits|           Campaigns|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6| 3/2/2015|25568| [twitter, LinkedIn]|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB...|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|5/12/2018|10568|       [twitter, FB]|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3| 6/7/2019| 7659|[web, twitter, FB...|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2| 5/5/2018| 8908| [twitter, LinkedIn]|\n",
      "|  1|    Jules|  Damji|https://tinyurl.1| 1/4/2016| 4535| [twitter, LinkedIn]|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blogsDF.sort(col(\"Id\").desc).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374edd7a",
   "metadata": {},
   "source": [
    "#### Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4da73d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.Row\n",
       "blogRow: org.apache.spark.sql.Row = [6,Reynold,Xin,https://tinyurl.6,255568,3/2/2015,[Ljava.lang.String;@1c66aea4]\n",
       "res7: Any = Reynold\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.Row\n",
    "\n",
    "val blogRow = Row(6, \"Reynold\", \"Xin\", \"https://tinyurl.6\", 255568, \"3/2/2015\", Array(\"twitter\", \"LinkedIn\"))\n",
    "\n",
    "blogRow(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c526c0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|       author|state|\n",
      "+-------------+-----+\n",
      "|Matei Zaharia|   CA|\n",
      "|  Reynold Xin|   CA|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rows: Seq[(String, String)] = List((Matei Zaharia,CA), (Reynold Xin,CA))\n",
       "authorsDF: org.apache.spark.sql.DataFrame = [author: string, state: string]\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rows = Seq((\"Matei Zaharia\", \"CA\"), (\"Reynold Xin\", \"CA\"))\n",
    "val authorsDF = rows.toDF(\"author\", \"state\")\n",
    "authorsDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8936aa",
   "metadata": {},
   "source": [
    "#### DataFrame Reader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c5510c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sampleDF: org.apache.spark.sql.DataFrame = [CallNumber: string, UnitID: string ... 26 more fields]\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sampleDF = spark\n",
    "    .read\n",
    "    .option(\"samplingRatio\", 0.001)\n",
    "    .option(\"header\", true)\n",
    "    .csv(\"\"\"./data/sf-fire-calls.csv\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29602685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res9: org.apache.spark.sql.DataFrame = [CallNumber: string, UnitID: string ... 26 more fields]\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59481239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fire_schema: org.apache.spark.sql.types.StructType = StructType(StructField(CallNumber,IntegerType,true),StructField(UnitID,StringType,true),StructField(IncidentNumber,IntegerType,true),StructField(CallType,StringType,true),StructField(CallDate,StringType,true),StructField(WatchDate,StringType,true),StructField(CallFinalDisposition,StringType,true),StructField(AvailableDtTm,StringType,true),StructField(Address,StringType,true),StructField(City,StringType,true),StructField(Zipcode,IntegerType,true),StructField(Battalion,StringType,true),StructField(StationArea,StringType,true),StructField(Box,StringType,true),StructField(OriginalPriority,StringType,true),StructField(Priority,StringType,true),StructField(FinalPriority,IntegerType,true),StructField(ALSUnit,BooleanType,true),StructField(Cal...\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fire_schema = StructType(Array(StructField(\"CallNumber\", IntegerType, true),\n",
    "                StructField(\"UnitID\", StringType, true),\n",
    "                StructField(\"IncidentNumber\", IntegerType, true),\n",
    "                StructField(\"CallType\", StringType, true),\n",
    "                StructField(\"CallDate\", StringType, true),\n",
    "                StructField(\"WatchDate\", StringType, true),\n",
    "                StructField(\"CallFinalDisposition\", StringType, true),\n",
    "                StructField(\"AvailableDtTm\", StringType, true),\n",
    "                StructField(\"Address\", StringType, true),\n",
    "                StructField(\"City\", StringType, true),\n",
    "                StructField(\"Zipcode\", IntegerType, true),\n",
    "                StructField(\"Battalion\", StringType, true),\n",
    "                StructField(\"StationArea\", StringType, true),\n",
    "                StructField(\"Box\", StringType, true),\n",
    "                StructField(\"OriginalPriority\", StringType, true),\n",
    "                StructField(\"Priority\", StringType, true),\n",
    "                StructField(\"FinalPriority\", IntegerType, true),\n",
    "                StructField(\"ALSUnit\", BooleanType, true),\n",
    "                StructField(\"CallTypeGroup\", StringType, true),\n",
    "                StructField(\"NumAlarms\", IntegerType, true),\n",
    "                StructField(\"UnitType\", StringType, true),\n",
    "                StructField(\"UnitSequenceInCallDispatch\", IntegerType,true),\n",
    "                StructField(\"FirePreventionDistrict\", StringType, true),\n",
    "                StructField(\"SupervisorDistrict\", StringType, true),\n",
    "                StructField(\"Neighborhood\", StringType,true),\n",
    "                StructField(\"Location\", StringType, true),\n",
    "                StructField(\"RowID\", StringType,true),\n",
    "                StructField(\"Delay\", FloatType, true)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7464cbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sf_fire_path: String = ./data/sf-fire-calls.csv\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sf_fire_path = \"./data/sf-fire-calls.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30489b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fire_df: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 26 more fields]\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fire_df = spark.read.schema(fire_schema)\n",
    "            .option(\"header\", \"true\")\n",
    "            .csv(sf_fire_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e6dc54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|CallNumber|UnitID|IncidentNumber|        CallType|  CallDate| WatchDate|CallFinalDisposition|       AvailableDtTm|             Address|City|Zipcode|Battalion|StationArea| Box|OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumAlarms|UnitType|UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|        Neighborhood|            Location|        RowID|    Delay|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|  20110016|   T13|       2003235|  Structure Fire|01/11/2002|01/10/2002|               Other|01/11/2002 01:51:...|2000 Block of CAL...|  SF|  94109|      B04|         38|3362|               3|       3|            3|  false|         NULL|        1|   TRUCK|                         2|                     4|                 5|     Pacific Heights|(37.7895840679362...|020110016-T13|     2.95|\n",
      "|  20110022|   M17|       2003241|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 03:01:...|0 Block of SILVER...|  SF|  94124|      B10|         42|6495|               3|       3|            3|   true|         NULL|        1|   MEDIC|                         1|                    10|                10|Bayview Hunters P...|(37.7337623673897...|020110022-M17|      4.7|\n",
      "|  20110023|   M41|       2003242|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 02:39:...|MARKET ST/MCALLIS...|  SF|  94102|      B03|         01|1455|               3|       3|            3|   true|         NULL|        1|   MEDIC|                         2|                     3|                 6|          Tenderloin|(37.7811772186856...|020110023-M41|2.4333334|\n",
      "|  20110032|   E11|       2003250|    Vehicle Fire|01/11/2002|01/10/2002|               Other|01/11/2002 04:16:...|APPLETON AV/MISSI...|  SF|  94110|      B06|         32|5626|               3|       3|            3|  false|         NULL|        1|  ENGINE|                         1|                     6|                 9|      Bernal Heights|(37.7388432849018...|020110032-E11|      1.5|\n",
      "|  20110043|   B04|       2003259|          Alarms|01/11/2002|01/10/2002|               Other|01/11/2002 06:01:...|1400 Block of SUT...|  SF|  94109|      B04|         03|3223|               3|       3|            3|  false|         NULL|        1|   CHIEF|                         2|                     4|                 2|    Western Addition|(37.7872890372638...|020110043-B04|3.4833333|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7abadbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parquet_path: String = ./data/save_parquet\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val parquet_path = \"./data/save_parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b5d13ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_df.write.format(\"parquet\").save(parquet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5aa03724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parquet_table: String = ./data/save_parquet_tbl\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val parquet_table = \"./data/save_parquet_tbl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b2ad136",
   "metadata": {},
   "outputs": [
    {
     "ename": "org.apache.spark.sql.catalyst.parser.ParseException",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "org.apache.spark.sql.catalyst.parser.ParseException:",
      "[PARSE_SYNTAX_ERROR] Syntax error at or near '.'.(line 1, pos 0)",
      "",
      "== SQL ==",
      "./data/save_parquet_tbl",
      "^^^",
      "",
      "  at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:257)",
      "  at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:98)",
      "  at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:54)",
      "  at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parseMultipartIdentifier(AbstractSqlParser.scala:54)",
      "  at org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:562)",
      "  ... 41 elided",
      ""
     ]
    }
   ],
   "source": [
    "fire_df.write.format(\"parquet\").saveAsTable(parquet_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2fe32a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "few_fire_df: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [IncidentNumber: int, AvailableDtTm: string ... 1 more field]\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val few_fire_df = (fire_df\n",
    "            .select(\"IncidentNumber\", \"AvailableDtTm\", \"CallType\")\n",
    "              .where($\"CallType\" =!= \"Medical Incident\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b993979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------+--------------+\n",
      "|IncidentNumber|AvailableDtTm         |CallType      |\n",
      "+--------------+----------------------+--------------+\n",
      "|2003235       |01/11/2002 01:51:44 AM|Structure Fire|\n",
      "|2003250       |01/11/2002 04:16:46 AM|Vehicle Fire  |\n",
      "|2003259       |01/11/2002 06:01:58 AM|Alarms        |\n",
      "|2003279       |01/11/2002 08:03:26 AM|Structure Fire|\n",
      "|2003301       |01/11/2002 09:46:44 AM|Alarms        |\n",
      "+--------------+----------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "few_fire_df.show(5, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c3847fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DistinctCallTypes|\n",
      "+-----------------+\n",
      "|               30|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_df.select(\"CallType\")\n",
    "        .where(col(\"CallType\").isNotNull)\n",
    "        .agg(countDistinct(\"CallType\") as \"DistinctCallTypes\")\n",
    "        .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cff4b6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newFireDF: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 26 more fields]\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val newFireDF = fire_df.withColumnRenamed(\"Delay\", \"ResponseDelayedinMins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b37e8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|ResponseDelayedinMins|\n",
      "+---------------------+\n",
      "|5.35                 |\n",
      "|6.25                 |\n",
      "|5.2                  |\n",
      "|5.6                  |\n",
      "|7.25                 |\n",
      "+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newFireDF.select(\"ResponseDelayedinMins\")\n",
    "        .where(col(\"ResponseDelayedinMins\") > 5)\n",
    "        .show(5, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "83e3a22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fireTsDF: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 26 more fields]\n"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fireTsDF = newFireDF\n",
    "    .withColumn(\"IncidentDate\", to_timestamp(col(\"CallDate\"), \"MM/dd/yyyy\"))\n",
    "    .drop(\"CallDate\")\n",
    "    .withColumn(\"OnWatchDate\", to_timestamp(col(\"WatchDate\"), \"MM/dd/yyyy\"))\n",
    "    .drop(\"WatchDate\")\n",
    "    .withColumn(\"AvailableDtTS\", to_timestamp(col(\"AvailableDtTm\"), \"MM/dd/yyyy hh:mm:ss a\"))\n",
    "    .drop(\"AvailableDtTm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c051bb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+\n",
      "|IncidentDate       |OnWatchDate        |AvailableDtTS      |\n",
      "+-------------------+-------------------+-------------------+\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 01:51:44|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 03:01:18|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 02:39:50|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 04:16:46|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 06:01:58|\n",
      "+-------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fireTsDF\n",
    "    .select(\"IncidentDate\",\"OnWatchDate\", \"AvailableDtTS\")\n",
    "    .show(5, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ebbaa703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|year(IncidentDate)|\n",
      "+------------------+\n",
      "|              2000|\n",
      "|              2001|\n",
      "|              2002|\n",
      "|              2003|\n",
      "|              2004|\n",
      "|              2005|\n",
      "|              2006|\n",
      "|              2007|\n",
      "|              2008|\n",
      "|              2009|\n",
      "|              2010|\n",
      "|              2011|\n",
      "|              2012|\n",
      "|              2013|\n",
      "|              2014|\n",
      "|              2015|\n",
      "|              2016|\n",
      "|              2017|\n",
      "|              2018|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fireTsDF\n",
    "    .select(year($\"IncidentDate\"))\n",
    "    .distinct()\n",
    "    .orderBy(year($\"IncidentDate\"))\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bcf9dc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+------+\n",
      "|CallType                       |count |\n",
      "+-------------------------------+------+\n",
      "|Medical Incident               |113794|\n",
      "|Structure Fire                 |23319 |\n",
      "|Alarms                         |19406 |\n",
      "|Traffic Collision              |7013  |\n",
      "|Citizen Assist / Service Call  |2524  |\n",
      "|Other                          |2166  |\n",
      "|Outside Fire                   |2094  |\n",
      "|Vehicle Fire                   |854   |\n",
      "|Gas Leak (Natural and LP Gases)|764   |\n",
      "|Water Rescue                   |755   |\n",
      "+-------------------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fireTsDF\n",
    "    .select(\"CallType\")\n",
    "    .where(col(\"CallType\").isNotNull) \n",
    "    .groupBy(\"CallType\")\n",
    "    .count()\n",
    "    .orderBy(desc(\"count\"))\n",
    "    .show(10, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "34ad85e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.{functions=>f}\n"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.{functions => f}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "de9939b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------------+--------------------------+--------------------------+\n",
      "|sum(NumAlarms)|avg(ResponseDelayedinMins)|min(ResponseDelayedinMins)|max(ResponseDelayedinMins)|\n",
      "+--------------+--------------------------+--------------------------+--------------------------+\n",
      "|        176170|         3.892364154521585|               0.016666668|                   1844.55|\n",
      "+--------------+--------------------------+--------------------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fireTsDF\n",
    "    .select(f.sum(\"NumAlarms\"), f.avg(\"ResponseDelayedinMins\"),\n",
    "            f.min(\"ResponseDelayedinMins\"), f.max(\"ResponseDelayedinMins\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8630cc55",
   "metadata": {},
   "source": [
    "## Dataset API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f0581f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.Row\n",
       "row: org.apache.spark.sql.Row = [350,true,learning spark 2e,null]\n"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.Row\n",
    "\n",
    "val row = Row(350, true, \"learning spark 2e\", null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4f8f6a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res30: String = learning spark 2e\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.getInt(0)\n",
    "\n",
    "row.getBoolean(1)\n",
    "\n",
    "row.getString(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c16a4a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class DeviceIoTData\n"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class DeviceIoTData (battery_level: Long, c02_level: Long,\n",
    "cca2: String, cca3: String, cn: String, device_id: Long,\n",
    "device_name: String, humidity: Long, ip: String, latitude: Double,\n",
    "lcd: String, longitude: Double, scale:String, temp: Long,\n",
    "timestamp: Long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1264f235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ds: org.apache.spark.sql.Dataset[DeviceIoTData] = [battery_level: bigint, c02_level: bigint ... 13 more fields]\n"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ds = spark.read\n",
    "        .json(\"./data/iot_devices.json\")\n",
    "        .as[DeviceIoTData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dccf82f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+----+----+-------------+---------+---------------------+--------+-------------+--------+------+---------+-------+----+-------------+\n",
      "|battery_level|c02_level|cca2|cca3|cn           |device_id|device_name          |humidity|ip           |latitude|lcd   |longitude|scale  |temp|timestamp    |\n",
      "+-------------+---------+----+----+-------------+---------+---------------------+--------+-------------+--------+------+---------+-------+----+-------------+\n",
      "|8            |868      |US  |USA |United States|1        |meter-gauge-1xbYRYcj |51      |68.161.225.1 |38.0    |green |-97.0    |Celsius|34  |1458444054093|\n",
      "|7            |1473     |NO  |NOR |Norway       |2        |sensor-pad-2n2Pea    |70      |213.161.254.1|62.47   |red   |6.15     |Celsius|11  |1458444054119|\n",
      "|2            |1556     |IT  |ITA |Italy        |3        |device-mac-36TWSKiT  |44      |88.36.5.1    |42.83   |red   |12.83    |Celsius|19  |1458444054120|\n",
      "|6            |1080     |US  |USA |United States|4        |sensor-pad-4mzWkz    |32      |66.39.173.154|44.06   |yellow|-121.32  |Celsius|28  |1458444054121|\n",
      "|4            |931      |PH  |PHL |Philippines  |5        |therm-stick-5gimpUrBB|62      |203.82.41.9  |14.58   |green |120.97   |Celsius|25  |1458444054122|\n",
      "+-------------+---------+----+----+-------------+---------+---------------------+--------+-------------+--------+------+---------+-------+----+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.show(5, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "477a4d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filterTempDS: org.apache.spark.sql.Dataset[DeviceIoTData] = [battery_level: bigint, c02_level: bigint ... 13 more fields]\n"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val filterTempDS = ds.filter({d => {d.temp > 30 && d.humidity > 70}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8cf97342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+----+----+-------------+---------+----------------------+--------+---------------+--------+------+---------+-------+----+-------------+\n",
      "|battery_level|c02_level|cca2|cca3|cn           |device_id|device_name           |humidity|ip             |latitude|lcd   |longitude|scale  |temp|timestamp    |\n",
      "+-------------+---------+----+----+-------------+---------+----------------------+--------+---------------+--------+------+---------+-------+----+-------------+\n",
      "|0            |1466     |US  |USA |United States|17       |meter-gauge-17zb8Fghhl|98      |161.188.212.254|39.95   |red   |-75.16   |Celsius|31  |1458444054129|\n",
      "|9            |986      |FR  |FRA |France       |48       |sensor-pad-48jt4eL    |97      |90.37.208.1    |43.88   |green |4.9      |Celsius|31  |1458444054151|\n",
      "|8            |1436     |US  |USA |United States|54       |sensor-pad-5410CWPrNb6|73      |204.15.64.249  |32.89   |red   |-117.13  |Celsius|34  |1458444054155|\n",
      "|4            |1090     |US  |USA |United States|63       |device-mac-63GL4xSaZbj|91      |66.198.198.1   |44.56   |yellow|-105.67  |Celsius|31  |1458444054162|\n",
      "|4            |1072     |PH  |PHL |Philippines  |81       |device-mac-81nsKomrRe |90      |222.127.71.1   |14.55   |yellow|121.04   |Celsius|31  |1458444054172|\n",
      "+-------------+---------+----+----+-------------+---------+----------------------+--------+---------------+--------+------+---------+-------+----+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filterTempDS.show(5, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1d267431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class DeviceTempByCountry\n"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class DeviceTempByCountry(temp: Long, device_name: String, device_id: Long, cca3: String)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eec4b9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dsTemp: org.apache.spark.sql.Dataset[DeviceTempByCountry] = [temp: bigint, device_name: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dsTemp = ds\n",
    "    .filter(d => {d.temp > 25})\n",
    "    .map(d => (d.temp, d.device_name, d.device_id, d.cca3))\n",
    "    .toDF(\"temp\", \"device_name\", \"device_id\", \"cca3\")\n",
    "    .as[DeviceTempByCountry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6877dfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------+---------+----+\n",
      "|temp|device_name          |device_id|cca3|\n",
      "+----+---------------------+---------+----+\n",
      "|34  |meter-gauge-1xbYRYcj |1        |USA |\n",
      "|28  |sensor-pad-4mzWkz    |4        |USA |\n",
      "|27  |sensor-pad-6al7RTAobR|6        |USA |\n",
      "+----+---------------------+---------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dsTemp.show(3, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f2c9264a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeviceTempByCountry(34,meter-gauge-1xbYRYcj,1,USA)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device: DeviceTempByCountry = DeviceTempByCountry(34,meter-gauge-1xbYRYcj,1,USA)\n"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val device = dsTemp.first()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4bcecb31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dsTemp2: org.apache.spark.sql.Dataset[DeviceTempByCountry] = [temp: bigint, device_name: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dsTemp2 = ds\n",
    "    .select($\"temp\", $\"device_name\", $\"device_id\", $\"cca3\")\n",
    "    .where(\"temp > 25\")\n",
    "    .as[DeviceTempByCountry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491ba5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
