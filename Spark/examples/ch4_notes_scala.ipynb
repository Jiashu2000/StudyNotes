{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95824e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://172.16.18.84:4040\n",
       "SparkContext available as 'sc' (version = 3.5.0, master = local[*], app id = local-1701128295444)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions._\n",
       "import org.apache.spark.sql.SparkSession\n",
       "import org.apache.spark.sql.types._\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.types._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f6478ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@7d477eb9\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession\n",
    "    .builder\n",
    "    .appName(\"ch4\")\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79308af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "csv_file: String = ./data/departuredelays.csv\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val csv_file = \"./data/departuredelays.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55acd168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [date: int, delay: int ... 3 more fields]\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.format(\"csv\")\n",
    "    .option(\"inferSchema\", true)\n",
    "    .option(\"header\", true)\n",
    "    .load(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d989f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"us_delay_flights_tbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eeee5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----------+\n",
      "|distance|origin|destination|\n",
      "+--------+------+-----------+\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "+--------+------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select distance, origin, destination\n",
    "from us_delay_flights_tbl\n",
    "where distance > 1000\n",
    "order by distance desc\n",
    "\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f73ceae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------+-----------+\n",
      "|   date|delay|origin|destination|\n",
      "+-------+-----+------+-----------+\n",
      "|2190925| 1638|   SFO|        ORD|\n",
      "|1031755|  396|   SFO|        ORD|\n",
      "|1022330|  326|   SFO|        ORD|\n",
      "|1051205|  320|   SFO|        ORD|\n",
      "|1190925|  297|   SFO|        ORD|\n",
      "|2171115|  296|   SFO|        ORD|\n",
      "|1071040|  279|   SFO|        ORD|\n",
      "|1051550|  274|   SFO|        ORD|\n",
      "|3120730|  266|   SFO|        ORD|\n",
      "|1261104|  258|   SFO|        ORD|\n",
      "+-------+-----+------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT date, delay, origin, destination\n",
    "FROM us_delay_flights_tbl\n",
    "WHERE delay > 120 AND ORIGIN = 'SFO' AND DESTINATION = 'ORD'\n",
    "ORDER by delay DESC\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f72dd3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----------+-------------+\n",
      "|delay|origin|destination|flight_delays|\n",
      "+-----+------+-----------+-------------+\n",
      "|  333|   ABE|        ATL|  long delays|\n",
      "|  305|   ABE|        ATL|  long delays|\n",
      "|  275|   ABE|        ATL|  long delays|\n",
      "|  257|   ABE|        ATL|  long delays|\n",
      "|  247|   ABE|        ATL|  long delays|\n",
      "|  247|   ABE|        DTW|  long delays|\n",
      "|  219|   ABE|        ORD|  long delays|\n",
      "|  211|   ABE|        ATL|  long delays|\n",
      "|  197|   ABE|        DTW|  long delays|\n",
      "|  192|   ABE|        ORD|  long delays|\n",
      "+-----+------+-----------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"\"\"\n",
    "select\n",
    "    delay, origin, destination,\n",
    "    case\n",
    "        when delay > 360 then 'very long delays'\n",
    "        when delay > 120 and delay < 360 then 'long delays'\n",
    "        when delay > 60 and delay < 120 then 'short delays'\n",
    "        when delay > 0 and delay < 60 then 'tolerable delays'\n",
    "        when delay == 0 then 'no delays'\n",
    "        else 'early'\n",
    "    end as flight_delays\n",
    "from us_delay_flights_tbl\n",
    "order by origin, delay desc\n",
    "\"\"\"\n",
    ").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70879519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res5: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE learn_spark_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dca31db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res6: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"USE learn_spark_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c8c42a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res13: String = file:/Users/jiashu/Documents/StudyNotes/spark/examples/spark-warehouse\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.sql.warehouse.dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aaf5d821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res16: String = in-memory\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.sql.catalogImplementation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9c794f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res17: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "create table us_delay_flights_tbl(data string, delay int,\n",
    "distance int, origin string, destination string)\n",
    "using csv options(path \"./data/departuredelays.csv\")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2064862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_sfo: org.apache.spark.sql.DataFrame = [date: int, delay: int ... 2 more fields]\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df_sfo = spark.sql(\"\"\"SELECT date, delay, origin, destination FROM\n",
    "us_delay_flights_tbl WHERE origin = 'SFO'\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "671c93c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sfo.createOrReplaceGlobalTempView(\"us_origin_airport_sfo_global_tmp_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4193b66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------+-----------+\n",
      "|   date|delay|origin|destination|\n",
      "+-------+-----+------+-----------+\n",
      "|1011250|   55|   SFO|        JFK|\n",
      "|1012230|    0|   SFO|        JFK|\n",
      "|1010705|   -7|   SFO|        JFK|\n",
      "|1010620|   -3|   SFO|        MIA|\n",
      "|1010915|   -3|   SFO|        LAX|\n",
      "|1011005|   -8|   SFO|        DFW|\n",
      "|1011800|    0|   SFO|        ORD|\n",
      "|1011740|   -7|   SFO|        LAX|\n",
      "|1012015|   -7|   SFO|        LAX|\n",
      "|1012110|   -1|   SFO|        MIA|\n",
      "+-------+-----+------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select * from global_temp.us_origin_airport_sfo_global_tmp_view\n",
    "\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "328ac294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res21: Boolean = true\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.dropGlobalTempView(\"us_origin_airport_sfo_global_tmp_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be8a4837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+----------------+--------------------+\n",
      "|          name|      catalog|     description|         locationUri|\n",
      "+--------------+-------------+----------------+--------------------+\n",
      "|       default|spark_catalog|default database|file:/Users/jiash...|\n",
      "|learn_spark_db|spark_catalog|                |file:/Users/jiash...|\n",
      "+--------------+-------------+----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.catalog.listDatabases().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "763fab27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+----------------+-----------+---------+-----------+\n",
      "|                name|      catalog|       namespace|description|tableType|isTemporary|\n",
      "+--------------------+-------------+----------------+-----------+---------+-----------+\n",
      "|us_delay_flights_tbl|spark_catalog|[learn_spark_db]|       NULL| EXTERNAL|      false|\n",
      "|us_delay_flights_tbl|         NULL|              []|       NULL|TEMPORARY|       true|\n",
      "+--------------------+-------------+----------------+-----------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.catalog.listTables().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f211b573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+--------+--------+-----------+--------+\n",
      "|       name|description|dataType|nullable|isPartition|isBucket|\n",
      "+-----------+-----------+--------+--------+-----------+--------+\n",
      "|       date|       NULL|     int|    true|      false|   false|\n",
      "|      delay|       NULL|     int|    true|      false|   false|\n",
      "|   distance|       NULL|     int|    true|      false|   false|\n",
      "|     origin|       NULL|  string|    true|      false|   false|\n",
      "|destination|       NULL|  string|    true|      false|   false|\n",
      "+-----------+-----------+--------+--------+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.catalog.listColumns(\"us_delay_flights_tbl\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "abb18cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file: String = ./data/summary-data/parquet/2010-summary.parquet\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val file = \"\"\"./data/summary-data/parquet/2010-summary.parquet\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc59d943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field]\n"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.format(\"parquet\").load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1d7eef17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "json_file: String = ./data/summary-data/json/*\n"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val json_file = \"\"\"./data/summary-data/json/*\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b11330d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field]\n"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.format(\"json\").load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "66fee2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "csv_file: String = ./data/summary-data/csv/*\n"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val csv_file = \"\"\"./data/summary-data/csv/*\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d0a0a12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schema: String = dest_country_name string, origin_country_name string, count int\n"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val schema = \"dest_country_name string, origin_country_name string, count int\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aed90c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [dest_country_name: string, origin_country_name: string ... 1 more field]\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.format(\"csv\")\n",
    "        .schema(schema)\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"mode\", \"FAILFAST\")\n",
    "        .option(\"nullValue\", \"\")\n",
    "        .load(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9c3909ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|dest_country_name|origin_country_name|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|    1|\n",
      "|    United States|            Ireland|  264|\n",
      "|    United States|              India|   69|\n",
      "|            Egypt|      United States|   24|\n",
      "|Equatorial Guinea|      United States|    1|\n",
      "|    United States|          Singapore|   25|\n",
      "|    United States|            Grenada|   54|\n",
      "|       Costa Rica|      United States|  477|\n",
      "|          Senegal|      United States|   29|\n",
      "|    United States|   Marshall Islands|   44|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ffd26e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avro_file: String = ./data/summary-data/avro/*\n"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val avro_file =  \"\"\"./data/summary-data/avro/*\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "402b55d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orc_file: String = ./data/summary-data/orc/*\n"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val orc_file = \"\"\"./data/summary-data/orc/*\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b1e0e364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field]\n"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.format(\"orc\")\n",
    "    .load(orc_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0fa2e115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|    1|\n",
      "|    United States|            Ireland|  264|\n",
      "|    United States|              India|   69|\n",
      "|            Egypt|      United States|   24|\n",
      "|Equatorial Guinea|      United States|    1|\n",
      "|    United States|          Singapore|   25|\n",
      "|    United States|            Grenada|   54|\n",
      "|       Costa Rica|      United States|  477|\n",
      "|          Senegal|      United States|   29|\n",
      "|    United States|   Marshall Islands|   44|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfc6ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
