{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b1774bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "724967dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.gutenberg.org/cache/epub/6130/pg6130.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71dc713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = urlopen(url).read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5975c58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1142775"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89924f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffThe Project Gutenberg eBook of The Iliad\\r\\n    \\r\\nThis ebook is for the use of anyone anywhere in the'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8e34cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89390f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ff80d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffThe', 'Project', 'Gutenberg', 'eBook', 'of', 'The', 'Iliad', 'This', 'ebook', 'is']\n"
     ]
    }
   ],
   "source": [
    "print(tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "037da1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "069fb736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.text.Text"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be8f6eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lives', 'or', 'condition', 'which', 'tradition', 'has', 'handed', 'down', 'to', 'us', ',', 'we', 'must', 'rather', 'consider', 'the', 'general', 'bearing', 'of', 'the', 'whole', 'narrative', ',', 'than', 'the', 'respective', 'probability', 'of', 'its', 'details', '.', 'It', 'is', 'unfortunate', 'for', 'us', ',', 'that', ',', 'of']\n"
     ]
    }
   ],
   "source": [
    "print(text[1020:1060])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7232fe6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Gutenberg™; Paradise Lost; Project Gutenberg; United States;\n",
      "Literary Archive; Gutenberg™ electronic; great Achilles; Gutenberg\n",
      "Literary; thou art; electronic works; blue-eyed maid; Archive\n",
      "Foundation; godlike Hector; native shore; great Ajax; Scæan gate;\n",
      "electronic work; Homeric poems; great Hector; Grecian train\n"
     ]
    }
   ],
   "source": [
    "text.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1fe49e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.bbc.com/news/world-us-canada-67662871\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39fc39b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = urlopen(url).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "289f671d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html><html><head><meta charSet=\"utf-8\"/><meta name'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html[:60 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "247728c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b246822",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = BeautifulSoup(html).get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c84b8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d31891b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Claudine', 'Gay', ':', 'Harvard', 'president', 'sorry', 'for', 'remarks', 'on', 'antisemitismHomeNewsSportBusinessInnovationCultureTravelEarthVideoLiveHomeNewsSportBusinessInnovationCultureTravelEarthVideoLiveHomeNewsSportBusinessInnovationCultureTravelEarthVideoLiveClaudine', 'Gay', ':', 'Harvard', 'president', 'sorry', 'for', 'remarks', 'on', 'antisemitismBy', 'Sam']\n"
     ]
    }
   ],
   "source": [
    "print(tokens[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e0782e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "39fa180b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chapter2.ipynb',\n",
       " 'chapter3.ipynb',\n",
       " 'chapter1.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " 'data']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eacaeddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter some texts: on an exceptionally hot evening early in July\n"
     ]
    }
   ],
   "source": [
    "s = input(\"enter some texts: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a48fd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you typed 8 words.\n"
     ]
    }
   ],
   "source": [
    "print(\"you typed\", len(nltk.word_tokenize(s)), \"words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "43d05481",
   "metadata": {},
   "outputs": [],
   "source": [
    "couplet = \"Rough winds do shake the darling buds of May,\"\\\n",
    "\"And Summer's lease hath all too short a date:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b7fb3242",
   "metadata": {},
   "outputs": [],
   "source": [
    "couplet = (\"Rough winds do shake the darling buds of May,\"\n",
    "\"And Summer's lease hath all too short a date:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a338f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rough winds do shake the darling buds of May,And Summer's lease hath all too short a date:\n"
     ]
    }
   ],
   "source": [
    "print(couplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d17ea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "couplet = \"\"\"Rough winds do shake the darling buds of May,\n",
    "And Summer's lease hath all too short a date:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4b3feafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rough winds do shake the darling buds of May,\n",
      "And Summer's lease hath all too short a date:\n"
     ]
    }
   ],
   "source": [
    "print(couplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "03b0c31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 4, 5, 6, 7, 6, 5, 4, 3, 2, 1]\n",
    "b = [' ' * 2 * (7 - i) + 'very' * i for i in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3162a41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            very\n",
      "          veryvery\n",
      "        veryveryvery\n",
      "      veryveryveryvery\n",
      "    veryveryveryveryvery\n",
      "  veryveryveryveryveryvery\n",
      "veryveryveryveryveryveryvery\n",
      "  veryveryveryveryveryvery\n",
      "    veryveryveryveryvery\n",
      "      veryveryveryvery\n",
      "        veryveryvery\n",
      "          veryvery\n",
      "            very\n"
     ]
    }
   ],
   "source": [
    "for line in b:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0452de70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "couplet[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc8eb5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "s1 = \"A\"\n",
    "print(ord(s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d42922ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🐀🐁🐂🐃🐄🐅🐆🐇🐈🐉🐊🐋🐌🐍🐎🐏🐐🐑🐒🐓🐔🐕🐖🐗🐘🐙🐚🐛🐜🐝🐞🐟🐠🐡🐢🐣🐤🐥🐦🐧🐨🐩🐪🐫🐬🐭🐮🐯🐰🐱🐲🐳🐴🐵🐶🐷🐸🐹🐺🐻🐼🐽🐾🐿👀👁👂👃👄👅👆👇👈👉👊👋👌👍👎👏👐👑👒👓👔👕👖👗👘👙👚👛👜👝👞👟👠👡👢👣"
     ]
    }
   ],
   "source": [
    "for i in range(128000, 128100, 1):\n",
    "    print(chr(i), end = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d030160e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👍\n"
     ]
    }
   ],
   "source": [
    "print(chr(128077))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7884acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👐\n"
     ]
    }
   ],
   "source": [
    "print(chr(128080))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3ee7478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "b'A'\n",
      "1\n",
      "[65]\n"
     ]
    }
   ],
   "source": [
    "print('A')\n",
    "print('A'.encode('utf-8'))\n",
    "print(len('A'.encode('utf-8')))\n",
    "print(list('A'.encode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4fe882d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🥰\n",
      "b'\\xf0\\x9f\\xa5\\xb0'\n",
      "4\n",
      "[240, 159, 165, 176]\n"
     ]
    }
   ],
   "source": [
    "print('🥰')\n",
    "print('🥰'.encode('utf-8'))\n",
    "print(len('🥰'.encode('utf-8')))\n",
    "print(list('🥰'.encode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffc0c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39e6f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = [w for w in nltk.corpus.words.words('en') if w.islower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0494af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210687"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5c5a337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abaissed',\n",
       " 'abandoned',\n",
       " 'abased',\n",
       " 'abashed',\n",
       " 'abatised',\n",
       " 'abed',\n",
       " 'aborted',\n",
       " 'abridged',\n",
       " 'abscessed',\n",
       " 'absconded',\n",
       " 'absorbed',\n",
       " 'abstracted',\n",
       " 'abstricted',\n",
       " 'accelerated',\n",
       " 'accepted',\n",
       " 'accidented',\n",
       " 'accoladed',\n",
       " 'accolated',\n",
       " 'accomplished',\n",
       " 'accosted']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# $match the end of the word \n",
    "\n",
    "[w for w in wordlist if re.search('ed$', w)][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e0fc22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abjectly',\n",
       " 'adjuster',\n",
       " 'dejected',\n",
       " 'dejectly',\n",
       " 'injector',\n",
       " 'majestic',\n",
       " 'objectee',\n",
       " 'objector',\n",
       " 'rejecter',\n",
       " 'rejector',\n",
       " 'unjilted',\n",
       " 'unjolted',\n",
       " 'unjustly']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# . wildcard matches any single character\n",
    "\n",
    "[w for w in wordlist if re.search('^..j..t..$', w)][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d065b139",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"i sent you an email , did you get the e-mail ?\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "53e10c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['email', 'e-mail']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ? symbol specifies that the previous character is optional\n",
    "\n",
    "[w for w in text if re.search('^e-?mail$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a234bc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gold', 'golf', 'hold', 'hole']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wordlist if re.search('^[ghi][mno][jlk][def]$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c834dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words = sorted(set(w for w in nltk.corpus.nps_chat.words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fa6e041d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6066"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chat_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "26a89b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'aaaaaaaaaaaaaaaaa', 'aaahhhh', 'ah', 'ahah', 'ahahah', 'ahh', 'ahhahahaha', 'ahhh', 'ahhhh', 'ahhhhhh', 'ahhhhhhhhhhhhhh', 'h', 'ha', 'haaa', 'hah', 'haha', 'hahaaa', 'hahah', 'hahaha', 'hahahaa', 'hahahah', 'hahahaha', 'hahahahaaa', 'hahahahahaha', 'hahahahahahaha', 'hahahahahahahahahahahahahahahaha', 'hahahhahah', 'hahhahahaha']\n"
     ]
    }
   ],
   "source": [
    "print([w for w in chat_words if re.search('^[ha]+$', w)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "de7a38fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['miiiiiiiiiiiiinnnnnnnnnnneeeeeeeeee',\n",
       " 'miiiiiinnnnnnnnnneeeeeeee',\n",
       " 'mine',\n",
       " 'mmmmmmmmiiiiiiiiinnnnnnnnneeeeeeee']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in chat_words if re.search('^m+i+n+e+$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "169d0fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '!!', '!!!', '!!!!', '!!!!!', '!!!!!!', '!!!!!!!', '!!!!!!!!', '!!!!!!!!!', '!!!!!!!!!!', '!!!!!!!!!!!', '!!!!!!!!!!!!!', '!!!!!!!!!!!!!!!!', '!!!!!!!!!!!!!!!!!!!!!!', '!!!!!!!!!!!!!!!!!!!!!!!', '!!!!!!!!!!!!!!!!!!!!!!!!!!!', '!!!!!!!!!!!!!!!!!!!!!!!!!!!!', '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!', '!!!!!!.', '!!!!!.']\n"
     ]
    }
   ],
   "source": [
    "print([w for w in chat_words if re.search('[^aeiouAEIOU]+$', w)][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5b26ea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsj = sorted(set(nltk.corpus.treebank.words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "58f4920f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.1', '0.2', '0.3', '0.4', '0.5', '0.7', '0.9', '1.1', '1.2', '1.4']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wsj if re.search('^[0-9]+\\.+[0-9]$', w)][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e88af87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C$', 'US$']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wsj if re.search('^[A-Z]+\\$$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7a258d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1614',\n",
       " '1637',\n",
       " '1787',\n",
       " '1901',\n",
       " '1903',\n",
       " '1917',\n",
       " '1925',\n",
       " '1929',\n",
       " '1933',\n",
       " '1934']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wsj if re.search('^[0-9]{4}$', w)][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aa3c4896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10-day',\n",
       " '10-lap',\n",
       " '10-year',\n",
       " '100-share',\n",
       " '12-point',\n",
       " '12-year',\n",
       " '14-hour',\n",
       " '15-day',\n",
       " '150-point',\n",
       " '190-point']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wsj if re.search('^[0-9]+-[a-z]{3,5}$', w)][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0d2ebdf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['black-and-white',\n",
       " 'bread-and-butter',\n",
       " 'father-in-law',\n",
       " 'machine-gun-toting',\n",
       " 'savings-and-loan']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wsj if re.search('^[a-z]{5,}-[a-z]{2,3}-[a-z]{,6}$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3e46c5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['62%-owned',\n",
       " 'Absorbed',\n",
       " 'According',\n",
       " 'Adopting',\n",
       " 'Advanced',\n",
       " 'Advancing',\n",
       " 'Alfred',\n",
       " 'Allied',\n",
       " 'Annualized',\n",
       " 'Anything']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wsj if re.search('(ed|ing)$', w)][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1f16afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'abcdefghijklmnopqrstuvwxyz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "238332e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'e', 'i', 'o', 'u']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'[aeiou]', word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c8dc2e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'io': 549, 'ea': 476, 'ie': 331, 'ou': 329, 'ai': 261, 'ia': 253, 'ee': 217, 'oo': 174, 'ua': 109, 'au': 106, ...})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FreqDist(vs for w in wsj \n",
    "              for vs in re.findall(r'[aeiou]{2,}', w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f8848c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp = r'^[AEIOUaeiou]+|[AEIOUaeiou]+$|[^AEIOUaeiou]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "406c3e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress(word):\n",
    "    pieces = re.findall(regexp, word)\n",
    "    return ''.join(pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "95327955",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_udhr = nltk.corpus.udhr.words(\"English-Latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8bc4cf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unvrsl Dclrtn of Hmn Rghts Prmble Whrs rcgntn of the inhrnt dgnty and\n",
      "of the eql and inlnble rghts of all mmbrs of the hmn fmly is the fndtn\n",
      "of frdm , jstce and pce in the wrld , Whrs dsrgrd and cntmp\n"
     ]
    }
   ],
   "source": [
    "print(nltk.tokenwrap(compress(w) for w in english_udhr)[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "03e59708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(word):\n",
    "    for suffix in ['ing', 'ly', 'ed', 'ious', 'ies', 'ive', 'es', 's', 'ment']:\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "57d5eac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ing']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^.*(ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e5e2e12b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['processing']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^.*(?:ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "94ee77d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('process', 'ing')]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^(.*)(ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b8c63595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('processe', 's')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^(.*)(ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8fe82ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('process', 'es')]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# *? non-greedy match\n",
    "re.findall(r'^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c085fbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg, nps_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ca910ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "moby = nltk.Text(gutenberg.words('melville-moby_dick.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c9b8d1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monied; nervous; dangerous; white; white; white; pious; queer; good;\n",
      "mature; white; Cape; great; wise; wise; butterless; white; fiendish;\n",
      "pale; furious; better; certain; complete; dismasted; younger; brave;\n",
      "brave; brave; brave\n"
     ]
    }
   ],
   "source": [
    "moby.findall(r\"<a>(<.*>)<man>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d1486080",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = nltk.Text(nps_chat.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "509b2122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you rule bro; telling you bro; u twizted bro\n"
     ]
    }
   ],
   "source": [
    "chat.findall(r\"<.*><.*><bro>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "64a37d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lol lol lol; lmao lol lol; lol lol lol; la la la la la; la la la; la\n",
      "la la; lovely lol lol love; lol lol lol.; la la la; la la la\n"
     ]
    }
   ],
   "source": [
    "chat.findall(r\"<l.*>{3,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8437ab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bae66e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "hobbies_learned = nltk.Text(brown.words(categories = ['hobbies', 'learned']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5c9650f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed and other activities; water and other liquids; tomb and other\n",
      "landmarks; Statues and other monuments; pearls and other jewels;\n",
      "charts and other items; roads and other features; figures and other\n",
      "objects; military and other areas; demands and other factors;\n",
      "abstracts and other compilations; iron and other metals\n"
     ]
    }
   ],
   "source": [
    "hobbies_learned.findall(r\"<\\w*><and><other><\\w*s>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4abc95cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords\n",
    " is no basis for a system of government. Supreme executive power derives from\n",
    " a mandate from the masses, not from some farcical aquatic ceremony.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "25ed460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "23597197",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fa269e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "lancaster = nltk.LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a9ef0560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['denni', ':', 'listen', ',', 'strang', 'women', 'lie', 'in', 'pond', 'distribut', 'sword', 'is', 'no', 'basi', 'for', 'a', 'system', 'of', 'govern', '.', 'suprem', 'execut', 'power', 'deriv', 'from', 'a', 'mandat', 'from', 'the', 'mass', ',', 'not', 'from', 'some', 'farcic', 'aquat', 'ceremoni', '.']\n"
     ]
    }
   ],
   "source": [
    "print([porter.stem(t) for t in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3fb5a48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['den', ':', 'list', ',', 'strange', 'wom', 'lying', 'in', 'pond', 'distribut', 'sword', 'is', 'no', 'bas', 'for', 'a', 'system', 'of', 'govern', '.', 'suprem', 'execut', 'pow', 'der', 'from', 'a', 'mand', 'from', 'the', 'mass', ',', 'not', 'from', 'som', 'farc', 'aqu', 'ceremony', '.']\n"
     ]
    }
   ],
   "source": [
    "print([lancaster.stem(t) for t in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5576ad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = nltk.Index((porter.stem(word), i) for (i, word) in enumerate(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c9bf4132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['denni', ':', 'listen', ',', 'strang', 'women', 'lie', 'in', 'pond', 'distribut', 'sword', 'is', 'no', 'basi', 'for', 'a', 'system', 'of', 'govern', '.', 'suprem', 'execut', 'power', 'deriv', 'from', 'mandat', 'the', 'mass', 'not', 'some', 'farcic', 'aquat', 'ceremoni'])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e661f05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('denni', [0]), (':', [1]), ('listen', [2]), (',', [3, 30]), ('strang', [4]), ('women', [5]), ('lie', [6]), ('in', [7]), ('pond', [8]), ('distribut', [9]), ('sword', [10]), ('is', [11]), ('no', [12]), ('basi', [13]), ('for', [14]), ('a', [15, 25]), ('system', [16]), ('of', [17]), ('govern', [18]), ('.', [19, 37]), ('suprem', [20]), ('execut', [21]), ('power', [22]), ('deriv', [23]), ('from', [24, 27, 32]), ('mandat', [26]), ('the', [28]), ('mass', [29]), ('not', [31]), ('some', [33]), ('farcic', [34]), ('aquat', [35]), ('ceremoni', [36])])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "08bb7310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   dog'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"%6s\" %'dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d5a4949a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog   '"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"%-6s\" %'dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "adcf2f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count, total = 3205, 9375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "46d19ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'accuray for 9375 is 34.1867%'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"accuray for %d is %2.4f%%\" %(total, 100 * count/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0323a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd= nltk.ConditionalFreqDist(\n",
    "    (genre, word)\n",
    "    for genre in brown.categories()\n",
    "    for word in brown.words(categories = genre)\n",
    ")\n",
    "\n",
    "genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']\n",
    "modals = ['can', 'could', 'may', 'might', 'must', 'will']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0faf9f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabulate(cfddist, words, categories):\n",
    "    print(\"%-16s\" % \"Category\", end = \" \")\n",
    "    for word in words:\n",
    "        print(\"%6s\" % word, end = \" \")\n",
    "    print()\n",
    "    \n",
    "    for category in categories:\n",
    "        print(\"%-16s\" %category, end = \" \")\n",
    "        for word in words:\n",
    "            print(\"%6d\" %cfddist[category][word], end = \" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8deee36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category            can  could    may  might   must   will \n",
      "news                 93     86     66     38     50    389 \n",
      "religion             82     59     78     12     54     71 \n",
      "hobbies             268     58    131     22     83    264 \n",
      "science_fiction      16     49      4     12      8     16 \n",
      "romance              74    193     11     51     45     43 \n",
      "humor                16     30      8      8      9     13 \n"
     ]
    }
   ],
   "source": [
    "tabulate(cfd, modals, genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "766eafe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   can'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"%6s\" % \"can\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "892b9147",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = open(\"data/output.txt\", 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f10b5b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set(nltk.corpus.genesis.words('english-kjv.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d83112b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words:\n",
    "    output_file.write(word + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b5dc4405",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1164a96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "saying = ['After', 'all', 'is', 'said', 'and', 'done', ',',\n",
    "          'more', 'is', 'said', 'than', 'done', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f49322ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After(5) all(3) is(2) said(4) and(3) done(4) ,(1) more(4) is(2) said(4) than(4) done(4) .(1) "
     ]
    }
   ],
   "source": [
    "for word in saying:\n",
    "    print(word + \"(\" + str(len(word)) + \")\", end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e1c20a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7a47021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "format = '%s_(%d),'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2c818be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pieces = [format %(word, len(word)) for word in saying]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "97e7723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ' '.join(pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a85ad856",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped = fill(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "77ab60e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After (5), all (3), is (2), said (4), and (3), done (4), , (1),\n",
      "more (4), is (2), said (4), than (4), done (4), . (1),\n"
     ]
    }
   ],
   "source": [
    "print(wrapped.replace(\"_\", ' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907e704b",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9703fc7b",
   "metadata": {},
   "source": [
    "### 1. Define a string s = 'colorless'. Write a Python statement that changes this to “colourless” using only the slice and concatenation operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d1be710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'colorless'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a6000502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'colourless'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[:4] + 'u' + s[4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56855021",
   "metadata": {},
   "source": [
    "### 2. We can use the slice notation to remove morphological endings on words. For example, 'dogs'[:-1] removes the last character of dogs, leaving dog. Use slice notation to remove the affixes from these words (we’ve inserted a hyphen to indicate the affix boundary, but omit this from your strings): dish-es, run-ning, nationality, un-do, pre-heat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "64f11fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "affixed = [('dishes', 2), \n",
    "           ('running', 4),\n",
    "           ('nationality', 5),\n",
    "           ('undo', 2),\n",
    "           ('preheat', 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f91df48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dish\n",
      "run\n",
      "nation\n",
      "un\n",
      "pre\n"
     ]
    }
   ],
   "source": [
    "for word, pos in affixed:\n",
    "    print(word[:-pos])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e55d933",
   "metadata": {},
   "source": [
    "### 3.We saw how we can generate an IndexError by indexing beyond the end of a string. Is it possible to construct an index that goes too far to the left, before the start of the string?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "14585bf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[182], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhello\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "'hello'[-7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dba707c",
   "metadata": {},
   "source": [
    "### 4. We can specify a “step” size for the slice. The following returns every second character within the slice: monty[6:11:2]. It also works in the reverse direction: monty[10:5:-2]. Try these for yourself, and then experiment with different step values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f37e1aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = \"hello. it is a  good day today. i will success!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c46e63f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l.ts'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents[2: 12: 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dd4225",
   "metadata": {},
   "source": [
    "### 5. What happens if you ask the interpreter to evaluate monty[::-1]? Explain why this is a reasonable result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "133378c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!sseccus lliw i .yadot yad doog  a si ti .olleh'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209f4e5c",
   "metadata": {},
   "source": [
    "### 6. Describe the class of strings matched by the following regular expressions:\n",
    "    a. [a-zA-Z]+\n",
    "    b. [A-Z][a-z]*\n",
    "    c. p[aeiou]{,2}t\n",
    "    d. \\d+(\\.\\d+)?\n",
    "    e. ([^aeiou][aeiou][^aeiou])*\n",
    "    f. \\w+|[^\\w\\s]+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d89b840d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{cAMELCASE} 6186258313 {hybr}1{d}\n"
     ]
    }
   ],
   "source": [
    "# a. [a-zA-Z]+\n",
    "\n",
    "# one or more alphabets\n",
    "\n",
    "nltk.re_show(\"[a-zA-Z]+\", \"cAMELCASE 6186258313 hybr1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b8077c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{I} think words beginning with {Uppercase} {Letters} will be matched, or any uppercase letters found in o{T}{H}{E}{R} positions.\n"
     ]
    }
   ],
   "source": [
    "# b. [A-Z][a-z]*\n",
    "\n",
    "# uppercase alphabet + zero or more lowercase alphabet\n",
    "\n",
    "test = 'I think words beginning with Uppercase Letters will be matched, ' \\\n",
    "       'or any uppercase letters found in oTHER positions.'\n",
    "\n",
    "nltk.re_show(\"[A-Z][a-z]*\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "1422c8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abaptiston',\n",
       " 'abepithymia',\n",
       " 'ableptical',\n",
       " 'ableptically',\n",
       " 'abrupt',\n",
       " 'abruptedly',\n",
       " 'abruption',\n",
       " 'abruptly',\n",
       " 'abruptness',\n",
       " 'absorpt',\n",
       " 'absorptance',\n",
       " 'absorptiometer',\n",
       " 'absorptiometric',\n",
       " 'absorption',\n",
       " 'absorptive',\n",
       " 'absorptively',\n",
       " 'absorptiveness',\n",
       " 'absorptivity',\n",
       " 'absumption',\n",
       " 'acalyptrate']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c. p[aeiou]{,2}t\n",
    "\n",
    "# with p, 0-2 vowels in the middle, then with t\n",
    "\n",
    "[w for w in wordlist if re.search(\"p[aeiou]{,2}t\", w)][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "622499c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1234', '12.34', 'example 123.4 in a string', '1-234', '12,4', '$12.34']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d. \\d+(\\.\\d+)?\n",
    "\n",
    "# numbers, with or without digits\n",
    "\n",
    "test = ['1234', '12.34', 'example 123.4 in a string', '1-234', '12,4', '$12.34']\n",
    "\n",
    "[w for w in test if re.search(r\"\\d+(\\.\\d+)?\", w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "6679fb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1.23}.{4}\n"
     ]
    }
   ],
   "source": [
    "nltk.re_show(r\"\\d+(\\.\\d+)?\", \"1.23.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "fe17a990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{babbabbabbab}{}a{pap}{}a{}\n"
     ]
    }
   ],
   "source": [
    "# e. ([^aeiou][aeiou][^aeiou])*\n",
    "\n",
    "# (non-vowel + vowel + non-vowel) repeat\n",
    "\n",
    "string = \"babbabbab\" \\\n",
    "         \"babapapa\"\n",
    "nltk.re_show(r'([^aeiou][aeiou][^aeiou])*', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "b1bd793f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{This} {RegExp} {needs} {a} {fairly} {long} {string} {to} {show} {what} {it} {can} {%#$^} {%&*} {do}{.}\n"
     ]
    }
   ],
   "source": [
    "# f. \\w+|[^\\w\\s]+\n",
    "\n",
    "# alphabets or non-alphabet and non-space\n",
    "\n",
    "string = \"This RegExp needs a fairly long string to show what it can %#$^ %&* do.\"\n",
    "nltk.re_show(r'\\w+|[^\\w\\s]+', string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5601561",
   "metadata": {},
   "source": [
    "### 7. Write regular expressions to match the following classes of strings:\n",
    "    a. A single determiner (assume that a, an, and the are the only determiners)\n",
    "    b. An arithmetic expression using integers, addition, and multiplication, such as\n",
    "    2*3+8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "6aa470c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think {a} relevant string like {the} one here is {an} example of what we need.\n"
     ]
    }
   ],
   "source": [
    "reg = r\"\\b[Aa]n?\\b|\\b[Tt]he\\b\"\n",
    "\n",
    "string = \"I think a relevant string like the one here is an example of what we need.\"\n",
    "\n",
    "nltk.re_show(reg, string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "72329251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2 * 3 + 8}\n"
     ]
    }
   ],
   "source": [
    "reg = r\"(\\d|[*+= ])+\"\n",
    "\n",
    "string = \"2 * 3 + 8\"\n",
    "\n",
    "nltk.re_show(reg, string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba0e024",
   "metadata": {},
   "source": [
    "### 8. Write a utility function that takes a URL as its argument, and returns the contents of the URL, with all HTML markup removed. Use urllib.urlopen to access the contents of the URL, e.g.: raw_contents = urllib.urlopen('http://www.nltk.org/').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "1b12293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "7037f074",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_contents = urllib.request.urlopen('http://www.nltk.org/').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f28797c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from unicodedata import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "cd847c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_url_contents(url):\n",
    "    html = urllib.request.urlopen(url).read().decode('utf8')\n",
    "    raw = BeautifulSoup(html, 'html.parser')\n",
    "    for r in raw(['script', 'style']):\n",
    "        r.extract()\n",
    "    \n",
    "    text = ' '.join(raw.stripped_strings)\n",
    "    return normalize('NFKD', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "5bf2067d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Laura Kuenssberg: Ukraine in 'mortal danger' without aid, Olena Zelenska warns Home News Sport Business Innovation Culture Travel Earth Video Live Home News Sport Business Innovation Culture Travel Ea\""
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.bbc.com/news/world-europe-67667035\"\n",
    "\n",
    "return_url_contents(url)[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd36481",
   "metadata": {},
   "source": [
    "### 9.Save some text into a file corpus.txt. Define a function load(f) that reads from the file named in its sole argument, and returns a string containing the text of the file.\n",
    "    \n",
    "    a. Use nltk.regexp_tokenize() to create a tokenizer that tokenizes the various kinds of punctuation in this text. Use one multiline regular expression inline comments, using the verbose flag (?x).\n",
    "    \n",
    "    b. Use nltk.regexp_tokenize() to create a tokenizer that tokenizes the following kinds of expressions: monetary amounts; dates; names of people and organizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2e8293",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
